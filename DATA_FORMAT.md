# Dataset Format Notes

This project uses preprocessed session data generated by `datasets/Amazon_preprocess.py`. The output artefacts live under `datasets/<dataset_name>/` and follow the conventions below.

## Train/Test Pickles

- Files: `train.txt`, `test.txt`
- Type: Python pickle created via `pickle.dump((sequences, labels))`
- Structure:
  - `sequences`: list of lists. Each inner list is a session prefix in **1-based item IDs**. Padding, where present, uses `0`.
  - `labels`: list of integers. Each entry is the ground-truth next item for the corresponding session prefix. IDs are 1-based and align with `sequences`.
- Sessions are truncated to max length 20 during preprocessing.

## Mapping Information

- Directory: `datasets/<dataset_name>/mapping/`
- Files:
  - `id_asin_info.pkl` / `id_asin_info.csv`
  - Columns/fields: `id`, `asin`, `url`, `title`, `category`
  - `id` matches the 1-based item IDs used in the train/test files.

## Optional Embeddings

If available, modality-specific embeddings are stored under `datasets/<dataset_name>/embeddings/`:

- `<modality>_matrix.npy` / `.pt`: shaped `[max_id + 1, dim]`
- Row 0 is zeros (padding); rows 1..N align with the item IDs.
- Modalities used in this project include `image`, `category`, `title`.

## Optional Global Graphs

Generated via `build_knn_global_graph.py` and stored in `datasets/<dataset_name>/global_graph/`.

Each `global_graph_<tag>.pkl` contains:
- `x`: padded feature matrix (same shape as in embeddings)
- `edge_index`: `[2, E]` array of 1-based node indices
- `edge_weight`: `[E]` cosine similarity weights (optional)
- `meta.num_nodes_including_padding`: expected item count + 1 (for padding)

Use this document when porting the preprocessed data into another repository (e.g., a clean GCE-GNN baseline) to ensure the model correctly interprets the session files and associated metadata.
